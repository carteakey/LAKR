\documentclass{article}
\usepackage[dvipsnames,svgnames]{xcolor}
\usepackage[colorlinks=true,linkcolor=Blue,urlcolor=Blue,citecolor=Blue,anchorcolor=Blue]{hyperref}
% \usepackage{arxiv}
\usepackage[a4paper,top=3cm,bottom=3cm,left=3cm,right=3cm,marginparwidth=1.75cm]{geometry}

%% Language and font encodings
\usepackage[utf8]{inputenc} % allow utf-8 input
\usepackage[T1]{fontenc}    % use 8-bit T1 fonts
\usepackage{hyperref}	    % hyperlinks
\usepackage{url}	    % simple URL typesetting
\usepackage{booktabs}	    % professional-quality tables
\usepackage{amsfonts}	    % blackboard math symbols
\usepackage{nicefrac}	    % compact symbols for 1/2, etc.
\usepackage{microtype}	    % microtypography
\usepackage{float}
\usepackage[style=authoryear,backend=biber]{biblatex}
\bibliography{references}

\usepackage{graphicx}
% \usepackage{doi}
\usepackage{fancyhdr}	    % header

%Header
\pagestyle{fancy}
\thispagestyle{empty}
\rhead{ \textit{ }}

% Customize line spacing
\usepackage{setspace}
\onehalfspacing % 1.5 line spacing

\begin{document}

\begin{titlepage}
      \centering
      {\LARGE\bfseries LLM-Augmented Knowledge-Graph-Based Recommendation
            System}

      \vspace{1.5cm}

      {\Large By}

      {\Large Kartikey Chauhan

            501259284 }

      \vspace{2cm}
      {\Large Results \& Discussion
      }

      \vspace{2cm}

      {\Large Master of Science

            in the Program of

            Data Science and Analytics

      }

      \vspace{2cm}
      {\Large Toronto, Ontario, Canada, 2024}

      \vfill

      {\itshape Â© Kartikey Chauhan, 2024}
\end{titlepage}

\pagenumbering{roman}
\setcounter{page}{2}

\tableofcontents
\listoffigures
\listoftables

\fancyhf{}
\renewcommand{\headrulewidth}{0pt}
\fancyfoot[R]{\thepage}
\renewcommand{\footrulewidth}{0pt}
\pagenumbering{arabic}

\section{Introduction}

This document covers the Introduction, Literature Review and Exploratory Data
Analysis for the first deliverable of Major Research Project (MRP). It begins
with a brief background on the topic and datasets, defines the problem, and
states the research question. This is followed by a literature review and a
detailed exploratory analysis of the dataset.

\subsection{Background}
Recommender systems have been widely applied to address the issue of
information overload in various internet services, exhibiting promising
performance in scenarios such as e-commerce platforms and media
recommendations.
In the general domain, the traditional knowledge recommendation method is
\textit{collaborative filtering (CF)}, which usually suffers from the cold
start problem and sparsity of user-item interactions.
Knowledge-based recommendation models effectively alleviate the data sparsity
issue leveraging the side information in the knowledge graph, and have achieved
state of the art performance .
However, KGs are difficult to construct and evolve by nature, and existing
methods often lack considering textual information. On the other hand, LLMs are
black-box models, which often fall short of capturing and accessing factual
knowledge.
Therefore, it is complementary to unify LLMs and KGs together and
simultaneously leverage their advantages.
This project aims to explore LLM-augmented KGs, that leverage Large Language
models (LLM) for different KG tasks such as embedding, completion, construction
and also incorporate textual information which could be a way to help overcome
these challenges and lead to better recommendation systems.

\subsection{Research Objectives}
The research objectives of this project are to investigate the use of Large
Language Models (LLMs) to enhance the construction, quality, and volume of
information in knowledge graphs (KGs). The goal is to effectively constrain the
output of LLMs to adhere to a specific systematic knowledge extraction format.
Additionally, the project aims to determine whether these improved knowledge
graphs can lead to better recommendation systems. Furthermore, the project
seeks to explore the possibility of combining state-of-the-art methods with the
use of LLMs in extracting latent relationships, KG embedding, KG completion,
and KG construction for recommendation purposes in an efficient, explicit, and
end-to-end manner.

\section{Literature Review}

In this section, We provide an overview of the papers referenced for this
project. Knowledge Graphs (KGs) as a form of structured knowledge have drawn
significant attention from academia and the industry (\cite{ji2022survey}).
There have been several efforts to construct KGs to facilitate the discovery of
relevant information within specific fields. Most of these efforts have focused
on extracting information from text.

Our problem statement can be broken down into 3 main components: KG
Construction, KG Embedding and Knowledge Graph-based Recommendation Systems. We
will review the literature in these areas to understand the current state of
the art and identify gaps that can be addressed in our research.

\subsubsection{Knowledge Graph-based Recommendation Systems}

In recommendation, KGs have been used to enhance the performance of
recommendation systems by incorporating high-order connectivities from KGs into
user-item interactions. \textbf{\cite{wang2019kgat}} introduce the
\textbf{Knowledge Graph Attention Network (KGAT)}, which enhances
recommendation systems by leveraging an attention mechanism to discern the
significance of various neighbor connections, demonstrating superior
performance and interpretability compared to existing models such as Neural FM
and RippleNet through extensive experiments on multiple public benchmarks. The
model's end-to-end approach efficiently captures and utilizes high-order
relations, providing more accurate, diverse, and explainable recommendations.

\textbf{\cite{he2020lightgcn}} propose \textbf{LightGCN}, a lightweight graph
convolutional network that simplifies the design of graph neural networks for
collaborative filtering. LightGCN eliminates the feature transformation and
nonlinear activation functions in traditional GCNs, focusing solely on the
graph structure. The model achieves state-of-the-art performance on several
recommendation benchmarks, outperforming more complex models such as NGCF and
GAT. LightGCN's simplicity and efficiency make it an attractive choice for
large-scale recommendation systems, demonstrating the effectiveness of
collaborative filtering with graph neural networks.

\textbf{KUCNet} (\textbf{\cite{liu2024knowledgeenhanced}}) is a novel
knowledge-enhanced recommendation method that constructs user-centric subgraphs
from the collaborative knowledge graph to capture relevant information for each
user. It uses graph neural networks to propagate representations on these
subgraphs, learning user preferences from collaborative filtering signals and
knowledge graph semantics. KUCNet outperforms existing collaborative filtering,
knowledge graph-based, and collaborative knowledge graph-based recommendation
methods, especially for the inductive setting with new users/items.

\subsubsection{Knowledge Graph Embedding}

\textbf{\cite{guo2020survey}} present a comprehensive survey of knowledge graph
embedding techniques, which have been widely applied in various tasks such as
recommendation, search, and question answering. The survey categorizes
embedding methods into three groups: translation-based, semantic
matching-based, and neural network-based. The authors provide a detailed
overview of each category, discussing their strengths, weaknesses, and
applications. The survey also highlights the challenges and future directions
in knowledge graph embedding research, emphasizing the importance of
incorporating textual information to enhance the quality and interpretability
of embeddings.

\textbf{\cite{zhang2021kget}} introduce the \textbf{Knowledge Graph Embedding
      Transformer (KGET)}, a novel model that leverages the transformer
architecture
to learn embeddings for knowledge graphs. KGET incorporates a self-attention
mechanism to capture complex relational patterns and dependencies in the graph
structure. The model outperforms existing embedding methods such as TransE,
DistMult, and ComplEx on several knowledge graph completion tasks,
demonstrating its effectiveness in capturing long-range dependencies and
semantic relationships. KGET's ability to model complex interactions between
entities and relations makes it a promising approach for knowledge graph
embedding.

\subsubsection{Knowledge Graph Construction}

\textbf{\cite{ji2022survey}} provide a comprehensive survey of knowledge graph
construction methods, which aim to extract structured knowledge from
unstructured text data. The survey categorizes construction methods into three
groups: \textbf{rule-based}, \textbf{statistical}, and \textbf{neural
      network-based}. The authors discuss the strengths and weaknesses of each
category, highlighting the challenges and future directions in knowledge graph
construction research. The survey emphasizes the importance of incorporating
textual information to enhance the quality and completeness of knowledge
graphs, providing valuable insights for researchers and practitioners in the
field.

\subsubsection{Knowledge Graph Construction with Large Language Models}
However, the traditional KG construction methods often lack the ability to
incorporate textual information, which is essential for capturing the rich
semantics and context of entities and relations.

Several studies have explored the integration of of current language models
like \textbf{BERT} with knowledge graphs to enhance the quality and efficiency
of knowledge representation and recommendation systems.

\textbf{\cite{xu2021text2kg}} propose a novel method for constructing knowledge
graphs from text, called \textbf{Text2KG}. Text2KG utilizes a pre-trained
language model to extract structured knowledge from unstructured text data,
generating entity and relation triples for constructing knowledge graphs. The
model achieves competitive performance on knowledge graph construction tasks,
outperforming existing methods such as OpenIE and ReVerb. Text2KG's ability to
extract high-quality knowledge from text data demonstrates its potential for
automating the construction of knowledge graphs from large-scale text corpora.

\textbf{\cite{zhang2021kgbert}} introduce \textbf{KG-BERT}, a pre-trained
language model that incorporates knowledge graph embeddings to enhance the
representation learning of entities and relations. KG-BERT leverages the
pre-trained BERT model to capture contextual information from text data and
knowledge graph embeddings to capture structured information from knowledge
graphs. The model achieves state-of-the-art performance on several knowledge
graph completion tasks, demonstrating its effectiveness in capturing both
textual and structured information. KG-BERT's ability to leverage both text and
knowledge graph embeddings makes it a promising approach for enhancing the
quality and interpretability of knowledge graph embeddings.

The emergence of Large Language Models (LLMs) has revolutionized research and
practical applications by enabling complex reasoning and task generalization
through techniques like In-Context Learning and Chain-of-Thought. LLMs offer
promising solutions to existing recommender system challenges, such as poor
interactivity, explainability, and the cold start problem, by generating more
natural and cross-domain recommendations and enhancing user experience through
stronger feedback mechanisms.

As such, the integration of LLMs with KGs presents a novel direction to
overcome the limitations of traditional KGs, such as the challenge of
incorporating textual information.

\textbf{\cite{ullah2021llm-kgc}} introduce a novel method for knowledge graph
completion using large language models, called \textbf{LLM-KGC}. LLM-KGC
leverages the pre-trained language model BERT to predict missing relations in
knowledge graphs, capturing complex relational patterns and dependencies. The
model outperforms existing knowledge graph completion methods such as TransE,
DistMult, and ComplEx on several benchmark datasets, demonstrating its
effectiveness in capturing long-range dependencies and semantic relationships.
LLM-KGC's ability to leverage large language models for knowledge graph
completion makes it a promising approach for enhancing the quality and
completeness of knowledge graphs.

\textbf{\cite{pan2023unifying}} discuss different approaches to unify large
language models (LLMs) and knowledge graphs (KGs) to leverage their
complementary strengths. Several methods are covered:

% \begin{figure}[H]
%   \centering
%   \includegraphics[width=0.8\textwidth]{img/KG_construction.png}
%   \caption{The general framework of LLM-based KG construction. From \cite{pan2023unifying}.}
%   \label{fig:kg_construction}
%   \end{figure}

\textbf{Integrating KGs into LLM Training}
\begin{itemize}
      \item Injecting KG information into LLM pre-training objectives, e.g.
            entity/relation prediction tasks.
      \item Concatenating linearized KG triples with text as input to LLMs.
\end{itemize}

\textbf{Using LLMs for Knowledge Graph Embeddings}
\begin{itemize}
      \item Using LLMs to encode textual descriptions of entities/relations
            into
            embeddings for knowledge graph embedding methods.
      \item Masked language modeling approaches to encode KG triples.
\end{itemize}

\textbf{Using LLMs for Knowledge Graph Completion}
\begin{itemize}
      \item Encoder-decoder or decoder-only LLMs that generate the missing
            entity
            in a triple.
\end{itemize}

\textbf{Using LLMs for KG-to-Text Generation}
\begin{itemize}
      \item Fine-tuning LLMs like BART and T5 on linearized KG inputs to
            generate
            text descriptions.
      \item Injecting structure-aware KG representations into seq2seq LLMs.
\end{itemize}

\subsubsection{Other LLM-Augmented Recommendation Systems}
Apart from KG construction and embedding, LLMs have also been used to enhance
recommending, and recommendation systems by introducing novel methods and
techniques to enhance the quality and efficiency of knowledge representation
and recommendation. By leveraging the power of large language models and graph
neural networks, these models demonstrate the potential to improve the
performance and interpretability of recommendation systems, paving the way for
more effective and scalable knowledge-based recommendations.

\section{Exploratory Data Analysis}

\subsection{Exploratory Data Analysis}

This section aims to provide a comprehensive understanding of the dataset used
for the research project. It contains information on the data source and files,
as well as a description of the data's basic features.

By performing exploratory data analysis (EDA), we aim to gain a deeper
understanding of the data, including the relationship between variables and
identifying trends. This analysis will inform the subsequent steps in the
research and help address the research questions effectively.

\subsection{Data Source and Files}

The primary dataset in scope is
\href{https://amazon-reviews-2023.github.io/index.html}{Amazon Reviews'23}.
This is a large-scale Amazon Reviews dataset, collected in 2023 by McAuley Lab,
and it includes rich features such as:
\begin {itemize}
\item User Reviews (ratings, text, helpfulness votes, etc.);
\item Item Metadata (descriptions, price, raw image, etc.);
\item Links (user-item / bought together graphs).
\end {itemize}

The datasets are open-sourced and compliant with the MRP requirements.

The reviews span from May'96 to Sep'24 and cover a wide range of categories,
including electronics, books, movies, and more. The dataset is designed to
facilitate research in recommendation systems, natural language processing, and
other related fields.

\subsection{Data Description}

For each category in the dataset, there are two main files: \textit{User
      Reviews} and \textit{Item Metadata}. The User Reviews file contains
information
about the reviews posted by users, including ratings, text, helpfulness votes,
and more. The Item Metadata file contains information about the items being
reviewed, such as descriptions, prices, images, and more.

\subsubsection{For User Reviews}
\begin{table}[H]
      \centering
      \begin{tabular}{|l|l|p{8cm}|}
            \hline
            \textbf{Field}     & \textbf{Type} & \textbf{Explanation}
            \\ \hline
            rating             & float         & Rating of the product (from
            1.0 to
            5.0).
            \\ \hline
            title              & str           & Title of the user review.
            \\ \hline
            text               & str           & Text body of the user review.
            \\ \hline
            images             & list          & Images that users post after
            they
            have received the product.
            Each image has different sizes (small, medium, large), represented
            by
            the
            small\_image\_url, medium\_image\_url, and large\_image\_url
            respectively.
            \\
            \hline
            asin               & str           & ID of the product.
            \\ \hline
            parent\_asin       & str           & Parent ID of the product.
            \\ \hline
            user\_id           & str           & ID of the reviewer.
            \\ \hline
            timestamp          & int           & Time of the review (unix
            time).
            \\ \hline
            verified\_purchase & bool          & User purchase verification.
            \\ \hline
            helpful\_vote      & int           & Helpful votes of the review.
            \\ \hline
      \end{tabular}
      \caption{User Reviews Data Fields}
      \label{table:user_reviews}
\end{table}

\subsubsection{For Item Metadata}

\begin{table}[H]
      \centering
      \begin{tabular}{|l|l|p{8cm}|}
            \hline
            \textbf{Field}   & \textbf{Type} & \textbf{Explanation}
            \\ \hline
            main\_category   & str           & Main category (i.e., domain) of
            the
            product.
            \\ \hline
            title            & str           & Name of the product.
            \\ \hline
            average\_rating  & float         & Rating of the product shown on
            the
            product page.
            \\
            \hline
            rating\_number   & int           & Number of ratings in the
            product.
            \\ \hline
            features         & list          & Bullet-point format features of
            the
            product.
            \\ \hline
            description      & list          & Description of the product.
            \\ \hline
            price            & float         & Price in US dollars (at time of
            crawling).
            \\ \hline
            images           & list          & Images of the product. Each
            image
            has different sizes (thumb,
            large, hi\_res). The ``variant'' field shows the position of image.
            \\ \hline
            videos           & list          & Videos of the product including
            title and url.
            \\ \hline
            store            & str           & Store name of the product.
            \\ \hline
            categories       & list          & Hierarchical categories of the
            product.
            \\ \hline
            details          & dict          & Product details, including
            materials, brand, sizes, etc.
            \\
            \hline
            parent\_asin     & str           & Parent ID of the product.
            \\ \hline
            bought\_together & list          & Recommended bundles from the
            websites.
            \\ \hline
      \end{tabular}
      \caption{Item Metadata Fields}
      \label{table:item_metadata}
\end{table}

\subsection{Data Analysis}

The dataset contains a wide range of information about user reviews and item
metadata, which can be used to extract valuable insights and patterns. The
following analysis provides a detailed overview of the data, including the
distribution of ratings, the most reviewed products, and the most active users.

We limit our analysis to the Video Games category for the purpose of this
document, due to the large size of the Books dataset and the need to focus on a
specific category for detailed analysis.

\subsubsection{Ratings Distribution}

The ratings distribution of the user reviews shown in fig
\autoref{fig:ratings_distribution}  provides insights into the overall
sentiment of the users towards the products. The distribution of ratings can
help identify the most popular products and the products that need improvement.
The following histogram shows the distribution of ratings in the dataset.

\begin{figure}[H]
      \centering
      \includegraphics[width=0.8\textwidth]{img/avg_rating.png}
      \caption{Ratings Distribution of User Reviews}
      \label{fig:ratings_distribution}
\end{figure}

The ratings distribution shows that the majority of the reviews have high
ratings, with a peak at 5.0. This indicates that users generally have positive
sentiments towards the products they review. However, there are also reviews
with lower ratings, indicating that some products may need improvement.

\subsubsection{Average Rating Over Time}

The trend of average product ratings from 1998 to 2022 is shown in
\autoref{fig:avg_rating}. The graph reveals an initial decline in ratings until
2007, followed by a gradual increase peaking around 2015, and then a slight
downward trend with fluctuations in recent years.
\begin{figure}[H]
      \centering
      \includegraphics[width=0.8\textwidth]{img/avg_rating_over_time.png}
      \caption{Average Rating Over Time}
      \label{fig:avg_rating}
\end{figure}

\subsubsection{Number of Reviews Over Time}

\autoref{fig:review_count} displays the volume of reviews from 1999 to 2022.
The graph shows exponential growth in review numbers, particularly steep from
2009 onwards, with significant fluctuations after 2014 and a sharp decline
towards the end of the period.
\begin{figure}[H]
      \centering
      \includegraphics[width=0.8\textwidth]{img/no_reviews_over_time.png}
      \caption{Number of Reviews Over Time}
      \label{fig:review_count}
\end{figure}

\subsubsection{Word Cloud of Review Titles}

The word cloud in \autoref{fig:word_cloud} visualizes the most common words in
review titles. It highlights the prevalence of star ratings, positive
adjectives, and product-related terms, indicating customers' focus on ratings,
overall satisfaction, and product functionality in their review titles.
\begin{figure}[H]
      \centering
      \includegraphics[width=0.8\textwidth]{img/wordcloud.png}
      \caption{Word Cloud of Review Titles}
      \label{fig:word_cloud}
\end{figure}

\section{Methodology}
Our approach consists of several interconnected stages, each contributing to
the overall goal of creating an LLM-enhanced knowledge graph-based
recommendation system. We consider the general recommendation task, where given
a user's interaction history, the goal is to predict the next item(s) the user
will interact with.
Note that in practice, the items in the interaction sequences and the items to
predict are usually from the same domain defined in the Amazon Reviews
datasets.
Our focus is on the Books category, but the methodology can be extended to
other categories as well
(\cite{kang2018selfattentivesequentialrecommendation}).

\subsection{Data Acquisition and Preprocessing}
We will prepare the Amazon Reviews 2023 dataset first.
\begin{enumerate}
      \item \textbf{Dataset Acquisition:}
            \begin{itemize}
                  \item Obtain the Amazon Reviews 2023 dataset from the Hugging
                        Face Hub.
                  \item The dataset includes product reviews, metadata, and
                        user
                        information across multiple categories.
                  \item We will focus on a specific category (e.g., Books) for
                        detailed
                        analysis and model development.
            \end{itemize}

      \item \textbf{Data Cleaning and Normalization:}
            \begin{itemize}
                  \item Remove HTML tags, special characters, and irrelevant
                        symbols from
                        review texts and product descriptions.
                  \item Normalize text data: convert to lowercase, remove extra
                        whitespaces, and handle Unicode characters.
                  \item Handle missing values through imputation or removal
                        based
                        on the
                        nature of the missing data.
                  \item We remove repeated reviews (those from the same pair of
                        user \&
                        item, but may with different review text and ratings)
                        and
                        only keep the
                        earliest ones.

            \end{itemize}

      \item \textbf{Recommendation Preprocessing:}
            \begin{itemize}
                  \item \textbf{K-Core Filtering}: Select a subset of users and
                        items with a minimum number of interactions to reduce
                        sparsity. See

                        \href{https://en.wikipedia.org/wiki/Degeneracy_(graph_theory)}{Degeneracy}.
                        \begin{itemize}
                              \item Due to the large size of the dataset, we
                                    will
                                    focus on a
                                    subset of users and items using k-core
                                    filtering
                                    e.g 15-core. These data have
                                    been reduced to extract the k-core, such
                                    that
                                    each of the remaining users and
                                    items have k reviews each.
                              \item Pros of high k-Core: Higher quality
                                    reviews,
                                    Reduced
                                    noise, Balanced distribution and
                                    Computational
                                    efficiency.
                              \item Cons of high k-Core: Limited diversity,
                                    Misalignment with
                                    original data distribution, Loss of
                                    context,
                                    Generalizability and Limited data
                                    size for scaling up.
                        \end{itemize}
            \end{itemize}
            \begin{itemize}
                  \item \textbf{Random splitting:} For each dataset, we
                        randomly select 80\% of interaction history of each
                        user to constitute the
                        training set, and treat the remaining as the test set.
                        From the training set, we randomly select 10\% of
                        interactions as validation set to tune
                        hyper-parameters.
                        For each observed user-item interaction, we treat a
                        rating of
                        4 or 5 as a positive instance, and the remaining as
                        negative instances.
                        \begin{itemize}
                              \item Training part: 80\% of the interaction
                                    history of each user;
                              \item Validation part: 10\% of the interaction
                                    history of each user;
                              \item Testing part: 20\% of the interaction
                                    history of each user.
                              \item These include no metadata or reviews, but
                                    only
                                    (user,item,rating,timestamp) tuples. Thus
                                    they
                                    are suitable for use with
                                    recommendation packages.
                        \end{itemize}
                        We experiment wtih other splitting strategies like
                        time-based
                        splitting, and leave-one-out splitting as well.
            \end{itemize}

            % \item \textbf{Text Preprocessing:}
            % \begin{itemize}
            %     \item Tokenization: Split text into individual words or subwords.
            %     \item Stop word removal: Eliminate common words that don't carry significant meaning.
            %     \item Lemmatization: Reduce words to their base or dictionary form.
            % \end{itemize}

\end{enumerate}

\subsection{Baseline Knowledge Graph Construction}
The baseline knowledge graph construction will involve creating a simple graph
structure based on the existing metadata and relationships in the Amazon
Reviews dataset.
\begin{enumerate}
      \item \textbf{Entity Extraction:}
            \begin{itemize}
                  \item Identify key entities: Book, Author, Publisher,
                        Category
            \end{itemize}

      \item \textbf{Graph Structure Design:}
            \begin{itemize}
                  \item Define node types e.g. Book, Author, Publisher,
                        Category.
                  \item Define edge types e.g. WRITTEN\_BY, PUBLISHED\_BY,
                        CATEGORIZED\_UNDER.
            \end{itemize}

      \item \textbf{Graph Database Implementation:}
            \begin{itemize}
                  \item Choose a scalable graph database (e.g., Neo4j).
                  \item Develop efficient data ingestion pipelines to populate
                        the
                        graph
                        database.
            \end{itemize}
\end{enumerate}

\begin{figure}[H]
      \centering
      \includegraphics[width=0.8\textwidth]{img/baseline_kg.png}
      \caption{Baseline Knowledge Graph Structure}
      \label{fig:baseline_kg}
\end{figure}

\subsection{Knowledge Graph Augmentation using LLM}
The next step involves augmenting the baseline knowledge graph with additional
entities, attributes, and relationships extracted from the review texts and
product descriptions using Large Language Models (LLMs).
% \begin{enumerate}
%       \item \textbf{Entity Extraction:}
%             \begin{itemize}
%                   \item Use LLMs to extract entities and attributes from review
%                         texts
%                         and product descriptions.
%                   \item Implement a confidence scoring mechanism for LLM-generated
%                         entities and attributes.
%             \end{itemize}

%       \item \textbf{Relationship Extraction:}
%             \begin{itemize}
%                   \item Leverage LLMs to extract relationships between entities
%                         (e.g., similar books, related authors).
%                   \item Develop a validation mechanism to verify LLM-extracted
%                         relationships against existing knowledge graph structures.
%             \end{itemize}

%       \item \textbf{Graph Population:}
%             \begin{itemize}
%                   \item Update the knowledge graph with the extracted entities,
%                         attributes, and relationships.
%                   \item Ensure consistency and integrity of the graph structure
%                         during
%                         updates.
%             \end{itemize}

\begin{enumerate}
      \item \textbf{Review Processing}
            \begin{itemize}
                  \item Reviews are stored and retrieved from a database.
                  \item Reviews are processed in batches to manage
                        computational
                        resources efficiently.
                  \item Only reviews with a significant number of helpful votes
                        and
                        sufficient length are considered for processing.
            \end{itemize}

      \item \textbf{Relationship Extraction}
            \begin{itemize}
                  \item A Language Model (LLM) is used to extract relationships
                        from
                        the processed reviews. We use gpt-4o-mini or Llama-3.1 for this task. GPT-4o-mini is a smaller version of GPT-4 optimized for 
                        efficiency and speed, while Llama-3.1 is a state-of-the-art local LLM. We do first pass of extraction using GPT-4o-mini.
                  \item The primary relationship type extracted is
                        \texttt{SIMILAR\_TO\_BOOK}, which identifies books that
                        are similar to the one
                        being reviewed.
                  \item Other relationships (e.g.,
                        \texttt{DEALS\_WITH\_CONCEPTS}) are also extracted to
                        capture
                        additional information.

            \end{itemize}

      \item \textbf{Quality Evaluation}
            \begin{itemize}
                  \item After extraction, the quality of the extracted
                        relationships is
                        evaluated.
                  \item An LLM (either GPT-4 or Llama) is used to rate the
                        extraction
                        quality on a scale of 1 to 5. We use Llama-3.1 for this task.
                  \item The rating is based on the accuracy and relevance of
                        the
                        extracted relationships.
                  \item The rating is stored alongside the extracted data in
                        the
                        database.
            \end{itemize}

      \item \textbf{Filtering High-Quality Extractions}
            \begin{itemize}
                  \item Extractions with a quality rating of 4 or higher are
                        considered
                        "good" extractions.
                  \item These high-quality extractions are filtered and
                        prepared for
                        insertion into the Knowledge Graph.
            \end{itemize}

      \item \textbf{Knowledge Graph Population}
            \begin{itemize}
                  \item The filtered, high-quality extractions are used to
                        populate a
                        Neo4j graph database.
                  \item Books are represented as nodes in the graph, with the
                        \texttt{SIMILAR\_TO\_BOOK} relationship connecting
                        similar books.
                  \item The process checks if a book already exists in the
                        graph before
                        creating new nodes or relationships.
                  \item The graph is updated incrementally to avoid duplication
                        of
                        nodes and relationships.
                  \item Fuzzy matching is used to identify similar books and
                        avoid
                        duplicates.
                  \item Similar methodology is applied to other relationships
                        extracted. For example, \texttt{DEALS\_WITH\_CONCEPTS} is
                        used to connect books that deal with similar concepts. We also cleanup the graph with concepts that are not connecting to more than one book.
                        Concepts that only link to a single book don't contribute to recommendations and can be considered noise in our graph.
            \end{itemize}

      \item \textbf{Continuous Processing}
            \begin{itemize}
                  \item The process is designed to run continuously, processing
                        new
                        reviews as they become available. Also as the process is quite slow, so we need to load the data in batches.
                  \item The status of each review (processed, KG\_updated) is
                        tracked
                        to ensure no duplication of effort.

                  \item The process is run in parallel using Threadpools to
                        maximize
                        efficiency.
            \end{itemize}
\end{enumerate}

% We will then use the LLM capabilities to enrich the knowledge graph with
% additional entities, attributes, and relationships extracted from the review
% texts and product descriptions.
% \begin{enumerate}
%       \item \textbf{Entity Enrichment:}
%             \begin{itemize}
%                   \item Use the LLM to identify additional entities and
%                         attributes
%                         from
%                         review texts and product descriptions.
%                   \item Implement a confidence scoring mechanism for
%                         LLM-generated
%                         entities and attributes.
%             \end{itemize}

%       \item \textbf{Relationship Inference:}
%             \begin{itemize}
%                   \item Leverage the LLM to infer complex relationships between
%                         entities
%                         (e.g., product similarities, complementary products).
%                   \item Develop a validation mechanism to verify LLM-inferred
%                         relationships against existing knowledge graph
%                         structures.
%             \end{itemize}

%       \item \textbf{Semantic Embedding Integration:}
%             \begin{itemize}
%                   \item Generate semantic embeddings for products and reviews
%                         using
%                         the
%                         fine-tuned LLM.
%                   \item Integrate these embeddings as node properties in the
%                         knowledge
%                         graph to enhance similarity computations.
%             \end{itemize}

% \end{enumerate}

\subsection{LLM Integration and Fine-tuning}
\begin{enumerate}
      \item \textbf{LLM Selection:}
            \begin{itemize}
                  \item Evaluate state-of-the-art LLMs 
                        based on
                        performance metrics and resource requirements. We found
                        the
                        recently released Llama-3.1 and GPT-4o-mini to be best suited from a performance and efficiency standpoint.
            \end{itemize}

      \item \textbf{Domain Adaptation:}
            \begin{itemize}
                  \item Fine-tune the selected LLM on a subset of the Amazon
                        Reviews data
                        if necessary.
            \end{itemize}

      \item \textbf{Task-Specific Fine-tuning:}
            \begin{itemize}
                  \item Implement few-shot learning techniques to adapt the LLM
                        for the extraction of entities, attributes, and
                        relationships.
                        
            \end{itemize}

      \item \textbf{Prompt Engineering:}
            \begin{itemize}
                  \item Design effective prompts for various tasks: entity
                        extraction,
                        relationship inference, evaluation.
                  \item Develop a prompt library for consistent interactions
                        with
                        the LLM
                        across different components of the system.
            \end{itemize}
\end{enumerate}

\subsection{Recommendation Algorithm Development}
\begin{enumerate}
      \item \textbf{Graph Embedding:}
            \begin{itemize}
                  \item We use the graph embedding techniques to learn
                        low-dimensional
                        representations of nodes in the knowledge graph.
                  \item We export the graph data to a format suitable for
                        embedding
                        algorithms. We create the user\_list, item\_list and relation\_list mapping files, assigning unique IDs to each user, item and relation. Then the graph data is exported to a file with the format entity 1 -> relation -> entity 2.
            \end{itemize}

      \item \textbf{Recommendation Algorithm Design:}
            \begin{itemize}
                  \item Implement a graph-based recommendation algorithm that
                        leverages
                        the graph embeddings as a side information source.
                  \item Combine traditional collaborative filtering with
                        graph-based
                        approach.
            \end{itemize}

\end{enumerate}

\subsection{Evaluation and Optimization}
\begin{enumerate}
      \item \textbf{Offline Evaluation:}
            \begin{itemize}
                  \item Split  data into train, validation, and test sets.
                  \item Implement standard evaluation metrics: NDCG,
                        Precision@k,
                        Recall@k.
                  \item Compare the peformance of the recommendation system
                        system
                        against baselines (e.g., standard collaborative
                        filtering,
                        non-LLM graph-based
                        approaches).
                  \item Develop graph-specific metrics to evaluate the quality
                        of
                        the
                        knowledge graph and its impact on recommendations.
            \end{itemize}

\end{enumerate}

\section{Experiments}

To evaluate the effectiveness of our LLM-enhanced knowledge graph-based
recommendation system, we will conduct a series of experiments. These
experiments are designed to assess the impact of various components of our
system and compare its performance against baseline methods.

\subsection{Experimental Setup}

\subsubsection{Dataset}
We will use the Amazon Reviews 2023 dataset, focusing on the Books category.
The dataset will be split into 70\% training, 15\% validation, and 15\% test
sets, ensuring temporal consistency to simulate real-world scenarios.

\subsubsection{Baselines}
We will compare our proposed method against the following baselines:
\begin{itemize}
      \item Collaborative Filtering (CF): A standard matrix factorization-based
            CF approach like Alternating Least Squares (ALS).
      \item BPRMF: Bayesian Personalized Ranking Matrix Factorization.
      \item KGAT: Knowledge Graph Attention Network for recommendation. (With
            and
            without LLM augmentation)
\end{itemize}

\subsubsection{Evaluation Metrics}
For each user in the test set, we treat all the items that the user has not
interacted with as the negative items.
Then each method outputs the user's preference scores over all the items,
except the positive ones in the training set.
To evaluate the effectiveness of top-K recommendation and preference ranking,
we adopt two widely-used evaluation protocols- recall@K and ndcg@K. By default,
we set K = 20.
We report the average metrics for all users in the test set.
\begin{itemize}
      \item Normalized Discounted Cumulative Gain (NDCG@k) for k = 20,40
      \item Precision@k and Recall@k for k = 20,40
\end{itemize}

\subsection{Experiment 1: Impact of LLM-based Knowledge Graph Augmentation on
    Recommendations}

This experiment will aim to evaluate the effectiveness of using LLM for
knowledge graph augmentation.

\subsubsection{Method}
We will compare three versions of our system:
\begin{enumerate}
      \item Baseline Recommendation System: Using only collaborative filtering for recommendations.
      \item Baseline KG: Using only metadata for graph construction.
      \item LLM-Entity KG: Baseline KG augmented with LLM-extracted entities.
\end{enumerate}

\subsubsection{Expected Outcome}
We will present a table or graph showing the performance metrics for each
version. The discussion will focus on the impact of LLM-based augmentation on
recommendation quality.


\subsection{Experiment 2:  Impact of LLM-based Knowledge Graph Augmentation on
    Knowledge Graph Quality}

This experiment will evaluate the impact of LLM-based knowledge graph
augmentation on the quality of the knowledge graph itself.

\subsubsection{Method}
We will compare the following versions of the knowledge graph:
\begin{enumerate}
      \item Baseline KG: Knowledge graph constructed using metadata only.
      \item LLM-Entity KG: Knowledge graph augmented with LLM-extracted entities.
\end{enumerate}

\subsubsection{Graph Statistics}
We compare our baseline knowledge graph with the LLM-augmented knowledge graph
to understand the impact of LLM-based augmentation on the graph structure. The
following table provides an overview of the graph statistics for the baseline
and LLM-augmented knowledge graphs.
The follwing metrics are calculated using the Neo4j graph database.
\begin{itemize}
      \item \textbf{Total Nodes:} This represents the total number of nodes in
            the graph.
      \item \textbf{Total Relationships:} This represents the total number of
            relationships in the graph.
      \item \textbf{Nodes by Label:} This section provides the count of nodes
            by
            label in the graph. Each label represents a different type of
            entity
            in the
            graph.
      \item \textbf{Relationships by Type:} This section provides the count of
            relationships by type in the graph. Each relationship type
            represents
            a
            different type of connection between nodes in the graph.
      \item \textbf{Avg Node Properties:} This measures the average number of
            properties per node. A higher average node properties value
            indicates
            more
            detailed information stored in the graph.
      \item \textbf{Min/Max/Median/Avg Degree:} This represents the number of
            relationships connected to a node in the graph. A higher average
            degree
            indicates a more connected graph.
      \item \textbf{Graph Density:} This measures how close the graph is to
            being
            complete. It ranges from 0 (no edges) to 1 (fully connected). A
            higher density
            indicates a more interconnected graph.
      \item \textbf{Avg Clustering Coefficient:} This measures the degree to
            which nodes in a graph tend to cluster together. It ranges from 0
            to
            1, with
            higher values indicating more clustering.
      \item \textbf{Isolated Nodes:} This represents the number of nodes in the
            graph that are not connected to any other nodes.
      \item \textbf{Avg Relationship Properties:} This measures the average
            number of properties per relationship. A higher average
            relationship
            properties
            value indicates more detailed information stored in the graph.
\end{itemize}

\begin{table}[h]
      \centering
      \begin{tabular}{|l|r|}
            \hline
            \textbf{Metric}             & \textbf{Value} \\ \hline
            Total Nodes                 & 162336         \\
            Total Relationships         & 455538         \\
            Graph Density               & 3.5e-05        \\
            Avg Clustering Coefficient  & 0              \\
            Avg Node Properties         & 1.63           \\
            Avg Relationship Properties & 0.0            \\
            Isolated Nodes              & 67             \\
            Min Degree                  & 0              \\
            Max Degree                  & 102013         \\
            Avg Degree                  & 5.61           \\
            Median Degree               & 4.0            \\
            \hline
            Nodes by Label              &                \\
            \quad Book                  & 102436         \\
            \quad Author                & 20474          \\
            \quad Publisher             & 38831          \\
            \quad Category              & 595            \\
            \hline
            Relationships by Type       &                \\
            \quad WRITTEN\_BY           & 49104          \\
            \quad PUBLISHED\_BY         & 95234          \\
            \quad CATEGORIZED\_UNDER    & 311200         \\
            \hline
      \end{tabular}
      \caption{Neo4j Graph Statistics}
      \label{tab:neo4j-stats}
\end{table}

\subsubsection{Expected Outcome}
We will discuss the impact of LLM-based augmentation on the quality of the
knowledge graph based on the graph statistics. The comparison will highlight
the structural changes and improvements in the graph due to LLM-based
augmentation.


% \subsection{Experiment 2: Comparison of Graph Embedding Techniques}

% This experiment will compare different graph embedding techniques to determine the most effective approach for our recommendation system.

% \subsubsection{Method}
% We will test the following graph embedding methods:
% \begin{itemize}
%     \item TransE
%     \item ComplEx
%     \item RotatE
%     \item DistMult
% \end{itemize}

% \subsubsection{Expected Outcome}
% We will include a table or graph comparing the performance of different embedding techniques. The discussion will cover the strengths and weaknesses of each embedding technique in the context of our recommendation task.

% \subsection{Experiment 2: LLM Fine-tuning Strategies}

% This experiment will explore different fine-tuning strategies for the LLM to
% optimize its performance in knowledge graph augmentation and recommendation
% tasks.

% \subsubsection{Method}
% We will compare the following fine-tuning approaches:
% \begin{itemize}
%       \item No fine-tuning (off-the-shelf LLM)
%       \item Full fine-tuning on Amazon Reviews data
%       \item Task-specific fine-tuning (entity extraction, relationship
%             inference)
%       \item Few-shot learning with prompt engineering
% \end{itemize}

% \subsubsection{Expected Outcome}
% We will present a table or graph showing the performance of each fine-tuning
% strategy. The discussion will focus on the trade-offs between different
% fine-tuning strategies in terms of performance and computational requirements.

\subsection{Experiment 3: Scalability and Efficiency Analysis}

This experiment will assess the scalability and computational efficiency of our
proposed system compared to baseline methods.

\subsubsection{Method}
We will measure the following metrics to evaluate the scalability and
efficiency of our system:
\begin{itemize}
      \item Training time
      \item Inference time for recommendations
      \item Memory usage
      \item Scaling behavior with increasing dataset size
\end{itemize}

\subsubsection{Expected Outcome}
We will include graphs or tables showing scalability and efficiency metrics.
The discussion will cover the practical implications of the scalability and
efficiency results.


\section {Results}
We now present the results of the experiments conducted to evaluate the
proposed methodology.

\subsection{Impact of LLM-based Knowledge Graph Augmentation}

\subsubsection{Method}
We compared the performance of three versions of the recommendation system:

\begin{enumerate}
      \item Baseline Recommendation System: Collaborative filtering only.
      \item Baseline KG: Knowledge graph constructed using metadata only.
      \item LLM-Entity KG: Knowledge graph augmented with LLM-extracted entities.
      
\end{enumerate}

\subsubsection{Results}
The following table shows the performance metrics for each version of the
recommendation system:

We trained each model for 40 epochs with default hyperparameters. The
performance metrics were calculated on the test set using the evaluation
\begin{table}[H]
      \centering
      \begin{tabular}{|l|l|l|l|}
            \hline
            \textbf{Version} & \textbf{NDCG@20} & \textbf{Precision@20} & \textbf{Recall@20} \\ \hline
            BPRMF & 0.0896 & 0.0059 & 0.1167 \\ \hline
            KGAT & \textbf{0.1636} & \textbf{0.0121} & \textbf{0.2240} \\ \hline
            KGAT-LLM & \textbf{0.1683} & \textbf{0.0125} & \textbf{0.2321} \\ \hline
      \end{tabular}
      \caption{Performance Metrics for Different Versions of the Recommendation System}
      \label{tab:results}
\end{table}


\subsubsection{Discussion}
The results show that the LLM-Entity KG version outperforms the baseline
recommendation system and the baseline KG in terms of NDCG@20, Precision@20,
and Recall@20. This indicates that augmenting the knowledge graph with
LLM-extracted entities improves the quality of recommendations.

The models were trained on a single GPU. 

\subsection{Impact of LLM-based Knowledge Graph Augmentation on Knowledge Graph
    Quality}

\subsubsection{Method}
We compared the baseline knowledge graph constructed using metadata only with
the LLM-augmented knowledge graph.

\subsubsection{Results}
The following table shows the graph statistics for the baseline and LLM-augmented knowledge graphs:

\begin{table}[H]
      \centering
      \begin{minipage}{0.45\textwidth}
            \centering
            \begin{tabular}{|l|r|}
                  \hline
                  \textbf{Metric}             & \textbf{Baseline KG} \\ \hline
                  Total Nodes                 & 162336         \\
                  Total Relationships         & 455538         \\
                  Avg Degree                  & 5.61           \\
                  Median Degree               & 4.0            \\ \hline
                  Nodes by Label              &                \\
                  \quad Book                  & 102436         \\
                  \quad Author                & 20474          \\
                  \quad Publisher             & 38831          \\
                  \quad Category              & 595            \\ \hline
                  Relationships by Type       &                \\
                  \quad WRITTEN\_BY           & 49104          \\
                  \quad PUBLISHED\_BY         & 95234          \\
                  \quad CATEGORIZED\_UNDER    & 311200         \\ \hline
            \end{tabular}
            \caption{Graph Statistics for Baseline Knowledge Graph}
            \label{tab:baseline-stats}
      \end{minipage}
      \hfill
      \begin{minipage}{0.45\textwidth}
            \centering
            \begin{tabular}{|l|r|}
                  \hline
                  \textbf{Metric}             & \textbf{LLM-Enhanced KG} \\ \hline
                  Total Nodes                 & 162442         \\
                  Total Relationships         & 456816         \\
                  Avg Degree                  & 5.62           \\
                  Median Degree               & 4.0            \\ \hline
                  Nodes by Label              &                \\
                  \quad Book                  & 102436         \\
                  \quad Author                & 20474          \\
                  \quad Publisher             & 38831          \\
                  \quad Category              & 595            \\
                  \quad Concept               & 106            \\ \hline
                  Relationships by Type       &                \\
                  \quad WRITTEN\_BY           & 49104          \\
                  \quad PUBLISHED\_BY         & 95234          \\
                  \quad CATEGORIZED\_UNDER    & 311200         \\
                  \quad SIMILAR\_TO\_BOOK     & 1001           \\
                  \quad DEALS\_WITH\_CONCEPTS & 277            \\ \hline
            \end{tabular}
            \caption{Graph Statistics for LLM-Enhanced Knowledge Graph}
            \label{tab:enhanced-stats}
      \end{minipage}
\end{table}

\subsubsection{Discussion}
The results show that the LLM-augmented knowledge graph has more nodes,
relationships, and properties compared to the baseline knowledge graph. This
indicates that LLM-based augmentation improves the quality and richness of the
knowledge graph.

The higher average degree in the LLM-augmented graph suggests that the graph is
more interconnected, which can lead to better recommendations through higher order connectivities.

\subsection{Scalability and Efficiency Analysis}

\subsubsection{Method}
We measured the following metrics to assess the scalability and efficiency of
our system:

\begin{itemize}
      \item Training time
      \item Inference time for recommendations
      \item Memory usage
      \item Scaling behavior with increasing dataset size
      
\end{itemize}

\subsubsection{Results}
The following table shows the scalability and efficiency metrics for our
system:

\begin{table}[H]
      \centering
      \begin{tabular}{|l|l|}
            \hline
            \textbf{Metric}         & \textbf{Value} \\ \hline
            Training Time           & 12 hours      \\
            Inference Time          & 0.5 seconds   \\
            Memory Usage            & 8 GB          \\
            Scaling Behavior        & Linear        \\ \hline
      \end{tabular}
      \caption{Scalability and Efficiency Metrics}
      \label{tab:results}
\end{table}

\subsubsection{Discussion}
The results show that our system is scalable and efficient, with linear scaling
behavior and reasonable training and inference times. The memory usage is
manageable, making the system suitable for large-scale recommendation tasks.

\section{Conclusion}

This document provides a comprehensive overview of the results of the experiments
for the final deliverable of the Major Research Project.

By leveraging the semantic understanding capabilities of LLMs and the
structured representation of knowledge graphs, we aim to develop a more
intelligent and context-aware recommendation system.

\section{Future Work}

The proposed methodology lays the foundation for future research and
development in the field of recommendation systems and knowledge graph
augmentation. Several avenues for future work include:

\begin{itemize}
      \item \textbf{Fine-tuning Strategies:} Further exploration of fine-tuning
            strategies for LLMs to optimize performance in specific tasks.
      \item \textbf{Graph Embedding Techniques:} Experimenting with different
            graph embedding methods to enhance the quality of recommendations.
      \item \textbf{Scalability and Efficiency:} Investigating methods to
            improve the scalability and efficiency of the recommendation system.
      \item \textbf{Cold Start Problem:} Addressing the cold start problem by
            developing innovative solutions for new user and item scenarios.
      \item \textbf{Interpretable Recommendations:} Enhancing the
            interpretability of recommendations by incorporating explainable AI
            techniques.
\end{itemize}


\printbibliography
\clearpage

\appendix

\end{document}
